{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28dba44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "\n",
    "# Conectar ao banco de dados MySQL via ODBC usando DSN\n",
    "dsn_name = 'vojoana'\n",
    "conn = pyodbc.connect(f'DSN={dsn_name};')\n",
    "\n",
    "# Query para buscar os dados\n",
    "query = \"\"\"\n",
    "SELECT ped_spvcodigo, ped_numero, ped_dtemissao, ped_pescodigo,  \n",
    "       pes_razao, pes_fantasia, ped_pesobruto, ped_stpcodigo\n",
    "FROM pedidos, pessoa \n",
    "WHERE ped_natcodigo IN ('VEN', 'VES', 'VIN', 'VIS')\n",
    "  AND ped_pescodigo = pes_codigo \n",
    "  AND ped_pescodigo <> 1 \n",
    "  AND ped_stpcodigo = 6 \n",
    "ORDER BY ped_dtemissao;\n",
    "\"\"\"\n",
    "\n",
    "# Executar a query e armazenar os resultados em um DataFrame\n",
    "df = pd.read_sql(query, conn)\n",
    "\n",
    "# Fechar a conexão\n",
    "conn.close()\n",
    "\n",
    "# Converter a coluna de data de emissão para o tipo datetime\n",
    "df['ped_dtemissao'] = pd.to_datetime(df['ped_dtemissao'])\n",
    "\n",
    "# Criar uma nova coluna 'mes_ano' para agrupar os pedidos por mês e ano\n",
    "df['mes_ano'] = df['ped_dtemissao'].dt.to_period('M')\n",
    "\n",
    "# Calcular o peso médio mensal por cliente\n",
    "df_grouped = df.groupby(['ped_pescodigo', 'pes_razao', 'pes_fantasia']).agg(\n",
    "    media_peso_mensal=('ped_pesobruto', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Função para segmentar os clientes\n",
    "def segmentar_cliente(media_peso):\n",
    "    if media_peso >= 400:\n",
    "        return 'CLIENTE OURO'\n",
    "    elif 200 <= media_peso < 400:\n",
    "        return 'CLIENTE PRATA'\n",
    "    elif 80 <= media_peso < 200:\n",
    "        return 'CLIENTE BRONZE'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Aplicar a segmentação\n",
    "df_grouped['segmento'] = df_grouped['media_peso_mensal'].apply(segmentar_cliente)\n",
    "\n",
    "# Filtrar clientes com peso médio mensal >= 80 kg\n",
    "df_filtered = df_grouped[df_grouped['segmento'].notnull()]\n",
    "\n",
    "# Exportar o DataFrame filtrado para um arquivo Excel\n",
    "df_filtered.to_excel('clientes_segmentados.xlsx', index=False)\n",
    "\n",
    "print(\"Arquivo Excel 'clientes_segmentados.xlsx' gerado com sucesso.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7181d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "\n",
    "# Conectar ao banco de dados MySQL via ODBC usando DSN\n",
    "dsn_name = 'vojoana'\n",
    "conn = pyodbc.connect(f'DSN={dsn_name};')\n",
    "\n",
    "# Executar consulta SQL\n",
    "query = \"\"\"\n",
    "SELECT ped_pescodigo, ped_dtemissao, pes_razao, pes_fantasia, ped_pesobruto\n",
    "FROM pedidos\n",
    "JOIN pessoa ON ped_pescodigo = pes_codigo\n",
    "WHERE ped_natcodigo IN ('VEN', 'VES', 'VIN', 'VIS') AND ped_pescodigo <> 1 AND ped_stpcodigo = 6;\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "conn.close()\n",
    "\n",
    "# Preparar dados\n",
    "df['ped_dtemissao'] = pd.to_datetime(df['ped_dtemissao'])\n",
    "df['mes_ano'] = df['ped_dtemissao'].dt.to_period('M')\n",
    "\n",
    "# Agrupar e calcular média mensal de peso por cliente\n",
    "df_grouped = df.groupby(['ped_pescodigo', 'pes_razao', 'pes_fantasia', 'mes_ano']).agg(total_peso=('ped_pesobruto', 'sum')).reset_index()\n",
    "df_final = df_grouped.groupby(['ped_pescodigo', 'pes_razao', 'pes_fantasia']).agg(media_peso_mensal=('total_peso', 'mean')).reset_index()\n",
    "\n",
    "# Segmentar clientes\n",
    "def segmentar(peso):\n",
    "    if peso >= 400:\n",
    "        return 'CLIENTE OURO'\n",
    "    elif peso >= 200:\n",
    "        return 'CLIENTE PRATA'\n",
    "    elif peso >= 80:\n",
    "        return 'CLIENTE BRONZE'\n",
    "\n",
    "df_final['segmento'] = df_final['media_peso_mensal'].apply(segmentar)\n",
    "df_final = df_final[df_final['segmento'].notnull()]\n",
    "\n",
    "# Exportar para Excel\n",
    "df_final.to_excel('Clientes_Segmentadosnov.xlsx', index=False)\n",
    "\n",
    "print(\"Arquivo Excel 'Clientes_Segmentadosnov.xlsx' gerado com sucesso.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bf1e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "\n",
    "# Configurar a conexão ODBC usando o DSN\n",
    "dsn_name = 'vojoana'\n",
    "connection = pyodbc.connect(f'DSN={dsn_name}')\n",
    "\n",
    "# Definir a query\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    fng_pescodigo,\n",
    "    DATEDIFF(fng_dtpagto, fng_dtvencto) AS atraso\n",
    "FROM\n",
    "    finang \n",
    "WHERE\n",
    "    fng_tiporecpag = 'R'\n",
    "    AND fng_situacao = 'L'\n",
    "\"\"\"\n",
    "\n",
    "# Ler os dados da query para um DataFrame\n",
    "df = pd.read_sql(query, connection)\n",
    "\n",
    "# Fechar a conexão\n",
    "connection.close()\n",
    "\n",
    "# Agrupar os dados por cliente e calcular o atraso médio\n",
    "df_grouped = df.groupby('fng_pescodigo', as_index=False)['atraso'].mean()\n",
    "\n",
    "# Renomear a coluna do atraso médio\n",
    "df_grouped.rename(columns={'atraso': 'atraso_medio'}, inplace=True)\n",
    "\n",
    "# Exportar para um arquivo Excel\n",
    "output_filename = 'atraso_medio_vojoana2.xlsx'\n",
    "df_grouped.to_excel(output_filename, index=False)\n",
    "\n",
    "print(f'Arquivo Excel gerado: {output_filename}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c54f3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "\n",
    "# Conectar ao banco de dados MySQL via ODBC usando DSN\n",
    "dsn_name = 'vojoana'\n",
    "conn = pyodbc.connect(f'DSN={dsn_name};')\n",
    "\n",
    "# Executar consulta SQL\n",
    "query = \"\"\"\n",
    "SELECT ped_pescodigo, ped_dtemissao, pes_razao, pes_fantasia, ped_pesobruto\n",
    "FROM pedidos\n",
    "JOIN pessoa ON ped_pescodigo = pes_codigo\n",
    "WHERE ped_natcodigo IN ('VEN', 'VES', 'VIN', 'VIS') AND ped_pescodigo <> 1 AND ped_stpcodigo = 6;\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "conn.close()\n",
    "\n",
    "# Preparar dados\n",
    "df['ped_dtemissao'] = pd.to_datetime(df['ped_dtemissao'])\n",
    "df['mes_ano'] = df['ped_dtemissao'].dt.to_period('M')\n",
    "\n",
    "# Agrupar e calcular média mensal de peso por cliente\n",
    "df_grouped = df.groupby(['ped_pescodigo', 'pes_razao', 'pes_fantasia', 'mes_ano']).agg(total_peso=('ped_pesobruto', 'sum')).reset_index()\n",
    "df_final = df_grouped.groupby(['ped_pescodigo', 'pes_razao', 'pes_fantasia']).agg(media_peso_mensal=('total_peso', 'mean')).reset_index()\n",
    "\n",
    "# Segmentar clientes\n",
    "def segmentar(peso):\n",
    "    if peso > 599:\n",
    "        return 'CLIENTE DIAMANTE'\n",
    "    elif peso >= 400:\n",
    "        return 'CLIENTE OURO'\n",
    "    elif peso >= 200:\n",
    "        return 'CLIENTE PRATA'\n",
    "    elif peso >= 80:\n",
    "        return 'CLIENTE BRONZE'\n",
    "    elif peso > 0:\n",
    "        return 'CLIENTE PROSPECT'\n",
    "\n",
    "df_final['segmento'] = df_final['media_peso_mensal'].apply(segmentar)\n",
    "df_final = df_final[df_final['segmento'].notnull()]\n",
    "\n",
    "# Exportar para Excel\n",
    "df_final.to_excel('Clientes_Segmentadosdez.xlsx', index=False)\n",
    "\n",
    "print(\"Arquivo Excel 'Clientes_Segmentadosdez.xlsx' gerado com sucesso.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a68dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "\n",
    "# Conectar ao banco de dados MySQL via ODBC usando DSN\n",
    "dsn_name = 'segvojoana'\n",
    "conn = pyodbc.connect(f'DSN={dsn_name};')\n",
    "\n",
    "# Etapa 1: Consulta para obter os dados necessários\n",
    "query = \"\"\"\n",
    "SELECT ped_pescodigo, ped_dtemissao, pes_razao, pes_fantasia, ped_pesobruto\n",
    "FROM pedidos\n",
    "JOIN pessoa ON ped_pescodigo = pes_codigo\n",
    "WHERE ped_natcodigo IN ('VEN', 'VES', 'VIN', 'VIS') AND ped_pescodigo <> 1 AND ped_stpcodigo = 6;\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "conn.close()\n",
    "\n",
    "# Etapa 2: Preparar os dados\n",
    "df['ped_dtemissao'] = pd.to_datetime(df['ped_dtemissao'])\n",
    "df['mes_ano'] = df['ped_dtemissao'].dt.to_period('M')\n",
    "\n",
    "# Agrupar e calcular média mensal de peso por cliente\n",
    "df_grouped = df.groupby(['ped_pescodigo', 'pes_razao', 'pes_fantasia', 'mes_ano']).agg(total_peso=('ped_pesobruto', 'sum')).reset_index()\n",
    "df_final = df_grouped.groupby(['ped_pescodigo', 'pes_razao', 'pes_fantasia']).agg(media_peso_mensal=('total_peso', 'mean')).reset_index()\n",
    "\n",
    "# Segmentar clientes\n",
    "def segmentar(peso):\n",
    "    if peso > 599:\n",
    "        return 4  # CLIENTE DIAMANTE\n",
    "    elif peso >= 400:\n",
    "        return 1  # CLIENTE OURO\n",
    "    elif peso >= 200:\n",
    "        return 2  # CLIENTE PRATA\n",
    "    elif peso >= 80:\n",
    "        return 3  # CLIENTE BRONZE\n",
    "    elif peso > 0:\n",
    "        return 5  # CLIENTE PROSPECT\n",
    "\n",
    "# Adicionar segmento baseado na média de peso mensal\n",
    "df_final['clc_codigo'] = df_final['media_peso_mensal'].apply(segmentar)\n",
    "\n",
    "# Filtrar clientes com segmento definido\n",
    "df_final = df_final[df_final['clc_codigo'].notnull()]\n",
    "\n",
    "# Etapa 3: Gerar o script SQL\n",
    "sql_commands = []\n",
    "for _, row in df_final.iterrows():\n",
    "    # Gerar comando SQL para atualizar a classificação\n",
    "    sql = f\"UPDATE pessoa SET pes_clccodigo = {row['clc_codigo']} WHERE pes_codigo = {row['ped_pescodigo']};\"\n",
    "    sql_commands.append(sql)\n",
    "\n",
    "# Salvar comandos SQL em um arquivo\n",
    "with open('atualizar_classificacao.sql', 'w', encoding='utf-8') as file:\n",
    "    file.write('\\n'.join(sql_commands))\n",
    "\n",
    "print(\"Arquivo SQL 'atualizar_classificacao.sql' gerado com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256748f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "\n",
    "# Conectar ao banco de dados MySQL via ODBC usando DSN\n",
    "dsn_name = 'segvojoana'\n",
    "conn = pyodbc.connect(f'DSN={dsn_name};')\n",
    "\n",
    "# Etapa 1: Consulta para obter os dados necessários\n",
    "query = \"\"\"\n",
    "SELECT ped_pescodigo, ped_dtemissao, pes_razao, pes_fantasia, ped_pesobruto, pes_clccodigo\n",
    "FROM pedidos\n",
    "JOIN pessoa ON ped_pescodigo = pes_codigo\n",
    "WHERE ped_natcodigo IN ('VEN', 'VES', 'VIN', 'VIS') AND ped_pescodigo <> 1 AND ped_stpcodigo = 6;\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "\n",
    "# Consultar classificações\n",
    "query_classificacoes = \"\"\"\n",
    "SELECT clc_codigo, clc_desc\n",
    "FROM classificapes;\n",
    "\"\"\"\n",
    "df_classificacoes = pd.read_sql(query_classificacoes, conn)\n",
    "\n",
    "# Fechar conexão após carregar os dados\n",
    "conn.close()\n",
    "\n",
    "# Criar um dicionário de mapeamento de código para descrição\n",
    "codigo_to_desc = df_classificacoes.set_index('clc_codigo')['clc_desc'].to_dict()\n",
    "\n",
    "# Etapa 2: Preparar os dados\n",
    "df['ped_dtemissao'] = pd.to_datetime(df['ped_dtemissao'])\n",
    "df['mes_ano'] = df['ped_dtemissao'].dt.to_period('M')\n",
    "\n",
    "# Agrupar e calcular média mensal de peso por cliente\n",
    "df_grouped = df.groupby(['ped_pescodigo', 'pes_razao', 'pes_fantasia', 'mes_ano']).agg(total_peso=('ped_pesobruto', 'sum')).reset_index()\n",
    "df_final = df_grouped.groupby(['ped_pescodigo', 'pes_razao', 'pes_fantasia']).agg(media_peso_mensal=('total_peso', 'mean')).reset_index()\n",
    "\n",
    "# Segmentar clientes\n",
    "def segmentar(peso):\n",
    "    if peso > 599:\n",
    "        return 4  # CLIENTE DIAMANTE\n",
    "    elif peso >= 400:\n",
    "        return 1  # CLIENTE OURO\n",
    "    elif peso >= 200:\n",
    "        return 2  # CLIENTE PRATA\n",
    "    elif peso >= 80:\n",
    "        return 3  # CLIENTE BRONZE\n",
    "    elif peso > 0:\n",
    "        return 5  # CLIENTE PROSPECT\n",
    "\n",
    "# Adicionar segmento baseado na média de peso mensal\n",
    "df_final['nova_clc_codigo'] = df_final['media_peso_mensal'].apply(segmentar)\n",
    "\n",
    "# Garantir que `df` tenha valores únicos para `ped_pescodigo`\n",
    "df_unique = df.drop_duplicates(subset='ped_pescodigo')\n",
    "\n",
    "# Adicionar descrição da classificação atual e nova\n",
    "df_final['desc_clc_atual'] = df_final['ped_pescodigo'].map(\n",
    "    df_unique.set_index('ped_pescodigo')['pes_clccodigo']\n",
    ").map(codigo_to_desc)\n",
    "df_final['pes_clccodigo'] = df_final['ped_pescodigo'].map(\n",
    "    df_unique.set_index('ped_pescodigo')['pes_clccodigo']\n",
    ")\n",
    "df_final['desc_clc_nova'] = df_final['nova_clc_codigo'].map(codigo_to_desc)\n",
    "\n",
    "# Identificar mudanças de classificação\n",
    "df_final['mudanca'] = df_final.apply(\n",
    "    lambda row: 'Upgrade' if row['nova_clc_codigo'] < row['pes_clccodigo'] else\n",
    "                'Downgrade' if row['nova_clc_codigo'] > row['pes_clccodigo'] else\n",
    "                'Sem alteração',\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Excluir clientes sem classificação inicial (nulos) que foram classificados como PROSPECT\n",
    "df_final = df_final[~((df_final['pes_clccodigo'].isna()) & (df_final['nova_clc_codigo'] == 5))]\n",
    "\n",
    "# Filtrar apenas clientes com mudanças\n",
    "df_mudancas = df_final[df_final['mudanca'] != 'Sem alteração']\n",
    "\n",
    "# Gerar relatório em Excel\n",
    "df_mudancas[['ped_pescodigo', 'pes_razao', 'pes_fantasia', 'desc_clc_atual', 'desc_clc_nova', 'mudanca']].to_excel(\n",
    "    'Relatorio_Alteracoes_Classificacao.xlsx', index=False\n",
    ")\n",
    "\n",
    "# Gerar script SQL para atualizar as classificações\n",
    "sql_commands = []\n",
    "for _, row in df_final.iterrows():\n",
    "    sql = f\"UPDATE pessoa SET pes_clccodigo = {row['nova_clc_codigo']} WHERE pes_codigo = {row['ped_pescodigo']};\"\n",
    "    sql_commands.append(sql)\n",
    "\n",
    "with open('atualizar_classificacao.sql', 'w', encoding='utf-8') as file:\n",
    "    file.write('\\n'.join(sql_commands))\n",
    "\n",
    "print(\"Relatório e script SQL gerados com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671f5a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "\n",
    "# Conectar ao banco de dados MySQL via ODBC usando DSN\n",
    "dsn_name = 'segvojoana'\n",
    "conn = pyodbc.connect(f'DSN={dsn_name};')\n",
    "\n",
    "# Etapa 1: Consulta para obter os dados necessários\n",
    "query = \"\"\"\n",
    "SELECT ped_pescodigo, ped_dtemissao, pes_razao, pes_fantasia, ped_pesobruto, pes_clccodigo\n",
    "FROM pedidos\n",
    "JOIN pessoa ON ped_pescodigo = pes_codigo\n",
    "WHERE ped_natcodigo IN ('VEN', 'VES', 'VIN', 'VIS') AND ped_pescodigo <> 1 AND ped_stpcodigo = 6;\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "\n",
    "# Consultar classificações\n",
    "query_classificacoes = \"\"\"\n",
    "SELECT clc_codigo, clc_desc\n",
    "FROM classificapes;\n",
    "\"\"\"\n",
    "df_classificacoes = pd.read_sql(query_classificacoes, conn)\n",
    "\n",
    "# Fechar conexão após carregar os dados\n",
    "conn.close()\n",
    "\n",
    "# Criar um dicionário de mapeamento de código para descrição\n",
    "codigo_to_desc = df_classificacoes.set_index('clc_codigo')['clc_desc'].to_dict()\n",
    "\n",
    "# Etapa 2: Preparar os dados\n",
    "df['ped_dtemissao'] = pd.to_datetime(df['ped_dtemissao'])\n",
    "df['mes_ano'] = df['ped_dtemissao'].dt.to_period('M')\n",
    "\n",
    "# Agrupar e calcular média mensal de peso por cliente\n",
    "df_grouped = df.groupby(['ped_pescodigo', 'pes_razao', 'pes_fantasia', 'mes_ano']).agg(total_peso=('ped_pesobruto', 'sum')).reset_index()\n",
    "df_final = df_grouped.groupby(['ped_pescodigo', 'pes_razao', 'pes_fantasia']).agg(media_peso_mensal=('total_peso', 'mean')).reset_index()\n",
    "\n",
    "# Segmentar clientes\n",
    "def segmentar(peso):\n",
    "    if peso > 599:\n",
    "        return 4  # CLIENTE DIAMANTE\n",
    "    elif peso >= 400:\n",
    "        return 1  # CLIENTE OURO\n",
    "    elif peso >= 200:\n",
    "        return 2  # CLIENTE PRATA\n",
    "    elif peso >= 80:\n",
    "        return 3  # CLIENTE BRONZE\n",
    "    elif peso > 0:\n",
    "        return 5  # CLIENTE PROSPECT\n",
    "\n",
    "# Adicionar segmento baseado na média de peso mensal\n",
    "df_final['nova_clc_codigo'] = df_final['media_peso_mensal'].apply(segmentar)\n",
    "\n",
    "# Garantir que `df` tenha valores únicos para `ped_pescodigo`\n",
    "df_unique = df.drop_duplicates(subset='ped_pescodigo')\n",
    "\n",
    "# Adicionar descrição da classificação atual e nova\n",
    "df_final['pes_clccodigo'] = df_final['ped_pescodigo'].map(\n",
    "    df_unique.set_index('ped_pescodigo')['pes_clccodigo']\n",
    ")\n",
    "df_final['desc_clc_atual'] = df_final['pes_clccodigo'].map(codigo_to_desc)\n",
    "df_final['desc_clc_nova'] = df_final['nova_clc_codigo'].map(codigo_to_desc)\n",
    "\n",
    "# Identificar mudanças de classificação\n",
    "def identificar_mudanca(row):\n",
    "    if pd.isna(row['desc_clc_atual']) and row['desc_clc_nova'] == 'CLIENTE PROSPECT':\n",
    "        return 'Upgrade'  # Novo cliente segmentado como PROSPECT\n",
    "    elif row['nova_clc_codigo'] < row['pes_clccodigo']:\n",
    "        return 'Upgrade'\n",
    "    elif row['nova_clc_codigo'] > row['pes_clccodigo']:\n",
    "        return 'Downgrade'\n",
    "    else:\n",
    "        return 'Sem alteração'\n",
    "\n",
    "df_final['mudanca'] = df_final.apply(identificar_mudanca, axis=1)\n",
    "\n",
    "# Filtrar apenas clientes com mudanças relevantes\n",
    "df_mudancas = df_final[df_final['mudanca'] != 'Sem alteração']\n",
    "\n",
    "# Gerar relatório em Excel com a média em KG atual\n",
    "df_mudancas[['ped_pescodigo', 'pes_razao', 'pes_fantasia', 'desc_clc_atual', 'desc_clc_nova', 'media_peso_mensal', 'mudanca']].to_excel(\n",
    "    'Relatorio_Alteracoes_Classificacao.xlsx', index=False\n",
    ")\n",
    "\n",
    "# Gerar script SQL para atualizar as classificações\n",
    "sql_commands = []\n",
    "for _, row in df_final.iterrows():\n",
    "    sql = f\"UPDATE pessoa SET pes_clccodigo = {row['nova_clc_codigo']} WHERE pes_codigo = {row['ped_pescodigo']};\"\n",
    "    sql_commands.append(sql)\n",
    "\n",
    "with open('atualizar_classificacao.sql', 'w', encoding='utf-8') as file:\n",
    "    file.write('\\n'.join(sql_commands))\n",
    "\n",
    "print(\"Relatório e script SQL gerados com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e1f0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "\n",
    "# Conectar ao banco de dados MySQL via ODBC usando DSN\n",
    "dsn_name = 'segvojoana'\n",
    "conn = pyodbc.connect(f'DSN={dsn_name};')\n",
    "\n",
    "# Etapa 1: Consulta para obter os dados necessários\n",
    "query = \"\"\"\n",
    "SELECT ped_pescodigo, ped_dtemissao, pes_razao, pes_fantasia, ped_pesobruto, pes_clccodigo\n",
    "FROM pedidos\n",
    "JOIN pessoa ON ped_pescodigo = pes_codigo\n",
    "WHERE ped_natcodigo IN ('VEN', 'VES', 'VIN', 'VIS') AND ped_pescodigo <> 1 AND ped_stpcodigo = 6;\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "\n",
    "# Consultar classificações\n",
    "query_classificacoes = \"\"\"\n",
    "SELECT clc_codigo, clc_desc\n",
    "FROM classificapes;\n",
    "\"\"\"\n",
    "df_classificacoes = pd.read_sql(query_classificacoes, conn)\n",
    "\n",
    "# Fechar conexão após carregar os dados\n",
    "conn.close()\n",
    "\n",
    "# Criar um dicionário de mapeamento de código para descrição\n",
    "codigo_to_desc = df_classificacoes.set_index('clc_codigo')['clc_desc'].to_dict()\n",
    "\n",
    "# Etapa 2: Preparar os dados\n",
    "df['ped_dtemissao'] = pd.to_datetime(df['ped_dtemissao'])\n",
    "df['mes_ano'] = df['ped_dtemissao'].dt.to_period('M')\n",
    "\n",
    "# Agrupar e calcular média mensal de peso por cliente\n",
    "df_grouped = df.groupby(['ped_pescodigo', 'pes_razao', 'pes_fantasia', 'mes_ano']).agg(total_peso=('ped_pesobruto', 'sum')).reset_index()\n",
    "df_final = df_grouped.groupby(['ped_pescodigo', 'pes_razao', 'pes_fantasia']).agg(media_peso_mensal=('total_peso', 'mean')).reset_index()\n",
    "\n",
    "# Segmentar clientes\n",
    "def segmentar(peso):\n",
    "    if peso > 599:\n",
    "        return 4  # CLIENTE DIAMANTE\n",
    "    elif peso >= 400:\n",
    "        return 1  # CLIENTE OURO\n",
    "    elif peso >= 200:\n",
    "        return 2  # CLIENTE PRATA\n",
    "    elif peso >= 80:\n",
    "        return 3  # CLIENTE BRONZE\n",
    "    elif peso > 0:\n",
    "        return 5  # CLIENTE PROSPECT\n",
    "\n",
    "# Adicionar segmento baseado na média de peso mensal\n",
    "df_final['nova_clc_codigo'] = df_final['media_peso_mensal'].apply(segmentar)\n",
    "\n",
    "# Garantir que `df` tenha valores únicos para `ped_pescodigo`\n",
    "df_unique = df.drop_duplicates(subset='ped_pescodigo')\n",
    "\n",
    "# Adicionar descrição da classificação atual e nova\n",
    "df_final['pes_clccodigo'] = df_final['ped_pescodigo'].map(\n",
    "    df_unique.set_index('ped_pescodigo')['pes_clccodigo']\n",
    ")\n",
    "df_final['desc_clc_atual'] = df_final['pes_clccodigo'].map(codigo_to_desc)\n",
    "df_final['desc_clc_nova'] = df_final['nova_clc_codigo'].map(codigo_to_desc)\n",
    "\n",
    "# Identificar mudanças de classificação\n",
    "def identificar_mudanca(row):\n",
    "    # Caso o cliente passe de sem classificação para qualquer classificação\n",
    "    if pd.isna(row['desc_clc_atual']) and pd.notna(row['desc_clc_nova']):\n",
    "        return 'Upgrade'  # Novo cliente segmentado\n",
    "    elif row['nova_clc_codigo'] < row['pes_clccodigo']:\n",
    "        return 'Upgrade'\n",
    "    elif row['nova_clc_codigo'] > row['pes_clccodigo']:\n",
    "        return 'Downgrade'\n",
    "    else:\n",
    "        return 'Sem alteração'\n",
    "\n",
    "df_final['mudanca'] = df_final.apply(identificar_mudanca, axis=1)\n",
    "\n",
    "# Filtrar apenas clientes com mudanças relevantes\n",
    "df_mudancas = df_final[df_final['mudanca'] != 'Sem alteração']\n",
    "\n",
    "# Gerar relatório em CSV com a vírgula como separador decimal\n",
    "df_mudancas[['ped_pescodigo', 'pes_razao', 'pes_fantasia', 'desc_clc_atual', 'desc_clc_nova', 'media_peso_mensal', 'mudanca']].to_csv(\n",
    "    'Relatorio_Alteracoes_Classificacao.csv', index=False, sep=';', decimal=',', encoding='utf-8'\n",
    ")\n",
    "\n",
    "# Gerar script SQL para atualizar as classificações\n",
    "sql_commands = []\n",
    "for _, row in df_final.iterrows():\n",
    "    sql = f\"UPDATE pessoa SET pes_clccodigo = {row['nova_clc_codigo']} WHERE pes_codigo = {row['ped_pescodigo']};\"\n",
    "    sql_commands.append(sql)\n",
    "\n",
    "with open('atualizar_classificacao.sql', 'w', encoding='utf-8') as file:\n",
    "    file.write('\\n'.join(sql_commands))\n",
    "\n",
    "print(\"Relatório em CSV e script SQL gerados com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e62117a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "\n",
    "# Conectar ao banco de dados MySQL via ODBC usando DSN\n",
    "dsn_name = 'segvojoana'\n",
    "conn = pyodbc.connect(f'DSN={dsn_name};')\n",
    "\n",
    "# Etapa 1: Consulta para obter os dados necessários\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    ped.ped_pescodigo, \n",
    "    ped.ped_dtemissao, \n",
    "    pes.pes_razao, \n",
    "    pes.pes_fantasia, \n",
    "    ped.ped_pesobruto, \n",
    "    pes.pes_clccodigo, \n",
    "    cli.cli_cclcodigoe, \n",
    "    ccl.ccl_desc AS carteira_cliente\n",
    "FROM \n",
    "    pedidos ped\n",
    "JOIN \n",
    "    pessoa pes ON ped.ped_pescodigo = pes.pes_codigo\n",
    "JOIN \n",
    "    cliente cli ON pes.pes_codigo = cli.cli_pescodigo\n",
    "LEFT JOIN \n",
    "    carteiracli ccl ON cli.cli_cclcodigoe = ccl.ccl_codigo\n",
    "WHERE \n",
    "    ped.ped_natcodigo IN ('VEN', 'VES', 'VIN', 'VIS') \n",
    "    AND ped.ped_pescodigo <> 1 \n",
    "    AND ped.ped_stpcodigo = 6;\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "\n",
    "# Consultar classificações\n",
    "query_classificacoes = \"\"\"\n",
    "SELECT clc_codigo, clc_desc\n",
    "FROM classificapes;\n",
    "\"\"\"\n",
    "df_classificacoes = pd.read_sql(query_classificacoes, conn)\n",
    "\n",
    "# Fechar conexão após carregar os dados\n",
    "conn.close()\n",
    "\n",
    "# Criar um dicionário de mapeamento de código para descrição\n",
    "codigo_to_desc = df_classificacoes.set_index('clc_codigo')['clc_desc'].to_dict()\n",
    "\n",
    "# Etapa 2: Preparar os dados\n",
    "df['ped_dtemissao'] = pd.to_datetime(df['ped_dtemissao'])\n",
    "df['mes_ano'] = df['ped_dtemissao'].dt.to_period('M')\n",
    "\n",
    "# Agrupar e calcular média mensal de peso por cliente\n",
    "df_grouped = df.groupby(['ped_pescodigo', 'pes_razao', 'pes_fantasia', 'mes_ano']).agg(total_peso=('ped_pesobruto', 'sum')).reset_index()\n",
    "df_final = df_grouped.groupby(['ped_pescodigo', 'pes_razao', 'pes_fantasia']).agg(media_peso_mensal=('total_peso', 'mean')).reset_index()\n",
    "\n",
    "# Segmentar clientes\n",
    "def segmentar(peso):\n",
    "    if peso > 599:\n",
    "        return 4  # CLIENTE DIAMANTE\n",
    "    elif peso >= 400:\n",
    "        return 1  # CLIENTE OURO\n",
    "    elif peso >= 200:\n",
    "        return 2  # CLIENTE PRATA\n",
    "    elif peso >= 80:\n",
    "        return 3  # CLIENTE BRONZE\n",
    "    elif peso > 0:\n",
    "        return 5  # CLIENTE PROSPECT\n",
    "\n",
    "# Adicionar segmento baseado na média de peso mensal\n",
    "df_final['nova_clc_codigo'] = df_final['media_peso_mensal'].apply(segmentar)\n",
    "\n",
    "# Garantir que `df` tenha valores únicos para `ped_pescodigo`\n",
    "df_unique = df.drop_duplicates(subset='ped_pescodigo')\n",
    "\n",
    "# Adicionar descrição da classificação atual e nova\n",
    "df_final['pes_clccodigo'] = df_final['ped_pescodigo'].map(\n",
    "    df_unique.set_index('ped_pescodigo')['pes_clccodigo']\n",
    ")\n",
    "df_final['desc_clc_atual'] = df_final['pes_clccodigo'].map(codigo_to_desc)\n",
    "df_final['desc_clc_nova'] = df_final['nova_clc_codigo'].map(codigo_to_desc)\n",
    "\n",
    "# Identificar mudanças de classificação\n",
    "def identificar_mudanca(row):\n",
    "    # Caso o cliente passe de sem classificação para qualquer classificação\n",
    "    if pd.isna(row['desc_clc_atual']) and pd.notna(row['desc_clc_nova']):\n",
    "        return 'Upgrade'  # Novo cliente segmentado\n",
    "    elif row['nova_clc_codigo'] < row['pes_clccodigo']:\n",
    "        return 'Upgrade'\n",
    "    elif row['nova_clc_codigo'] > row['pes_clccodigo']:\n",
    "        return 'Downgrade'\n",
    "    else:\n",
    "        return 'Sem alteração'\n",
    "\n",
    "df_final['mudanca'] = df_final.apply(identificar_mudanca, axis=1)\n",
    "\n",
    "# Filtrar apenas clientes com mudanças relevantes\n",
    "df_mudancas = df_final[df_final['mudanca'] != 'Sem alteração']\n",
    "\n",
    "# Adicionar informações da carteira ao relatório\n",
    "df_mudancas = df_mudancas.merge(\n",
    "    df[['ped_pescodigo', 'carteira_cliente']].drop_duplicates(),\n",
    "    on='ped_pescodigo',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Gerar relatório em CSV com a vírgula como separador decimal\n",
    "df_mudancas[['ped_pescodigo', 'pes_razao', 'pes_fantasia', 'carteira_cliente', 'desc_clc_atual', 'desc_clc_nova', 'media_peso_mensal', 'mudanca']].to_csv(\n",
    "    'Relatorio_Alteracoes_Classificacao.csv', index=False, sep=';', decimal=',', encoding='utf-8'\n",
    ")\n",
    "\n",
    "# Gerar script SQL para atualizar as classificações\n",
    "sql_commands = []\n",
    "for _, row in df_final.iterrows():\n",
    "    sql = f\"UPDATE pessoa SET pes_clccodigo = {row['nova_clc_codigo']} WHERE pes_codigo = {row['ped_pescodigo']};\"\n",
    "    sql_commands.append(sql)\n",
    "\n",
    "with open('atualizar_classificacao.sql', 'w', encoding='utf-8') as file:\n",
    "    file.write('\\n'.join(sql_commands))\n",
    "\n",
    "print(\"Relatório em CSV e script SQL gerados com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7553cb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Obter a data atual\n",
    "data_atualizacao = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "# Adicionar a coluna de data de atualização\n",
    "df_final['data_atualizacao'] = data_atualizacao\n",
    "\n",
    "# Filtrar apenas clientes com mudanças relevantes\n",
    "df_mudancas = df_final[df_final['mudanca'] != 'Sem alteração']\n",
    "\n",
    "# Adicionar informações da carteira ao relatório\n",
    "df_mudancas = df_mudancas.merge(\n",
    "    df[['ped_pescodigo', 'carteira_cliente']].drop_duplicates(),\n",
    "    on='ped_pescodigo',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Gerar relatório em CSV com a vírgula como separador decimal\n",
    "df_mudancas[['ped_pescodigo', 'pes_razao', 'pes_fantasia', 'carteira_cliente', 'desc_clc_atual', 'desc_clc_nova', 'media_peso_mensal', 'mudanca', 'data_atualizacao']].to_csv(\n",
    "    'Relatorio_Alteracoes_Classificacao.csv', index=False, sep=';', decimal=',', encoding='utf-8'\n",
    ")\n",
    "\n",
    "# Gerar script SQL para atualizar as classificações\n",
    "sql_commands = []\n",
    "for _, row in df_final.iterrows():\n",
    "    sql = f\"UPDATE pessoa SET pes_clccodigo = {row['nova_clc_codigo']}, data_atualizacao = '{data_atualizacao}' WHERE pes_codigo = {row['ped_pescodigo']};\"\n",
    "    sql_commands.append(sql)\n",
    "\n",
    "with open('atualizar_classificacao.sql', 'w', encoding='utf-8') as file:\n",
    "    file.write('\\n'.join(sql_commands))\n",
    "\n",
    "print(\"Relatório em CSV e script SQL gerados com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de94f08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 390, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\AppData\\Local\\Temp\\ipykernel_39524\\956150992.py\", line 2, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\pandas\\__init__.py\", line 80, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\pandas\\core\\api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\arrow\\__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\arrow\\array.py\", line 50, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\__init__.py\", line 8, in <module>\n",
      "    from pandas.core.ops.array_ops import (\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py\", line 56, in <module>\n",
      "    from pandas.core.computation import expressions\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py\", line 21, in <module>\n",
      "    from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\check.py\", line 5, in <module>\n",
      "    ne = import_optional_dependency(\"numexpr\", errors=\"warn\")\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\pandas\\compat\\_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\numexpr\\__init__.py\", line 24, in <module>\n",
      "    from numexpr.interpreter import MAX_THREADS, use_vml, __BLOCK_SIZE1__\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 390, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\AppData\\Local\\Temp\\ipykernel_39524\\956150992.py\", line 2, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\pandas\\__init__.py\", line 80, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\pandas\\core\\api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\arrow\\__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\arrow\\array.py\", line 64, in <module>\n",
      "    from pandas.core.arrays.masked import BaseMaskedArray\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py\", line 60, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py\", line 52, in <module>\n",
      "    bn = import_optional_dependency(\"bottleneck\", errors=\"warn\")\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\pandas\\compat\\_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\Gabriel D. Barros\\anaconda3\\lib\\site-packages\\bottleneck\\__init__.py\", line 7, in <module>\n",
      "    from .move import (move_argmax, move_argmin, move_max, move_mean, move_median,\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gabriel D. Barros\\AppData\\Local\\Temp\\ipykernel_39524\\956150992.py:34: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relatório em CSV e script SQL gerados com sucesso!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gabriel D. Barros\\AppData\\Local\\Temp\\ipykernel_39524\\956150992.py:41: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_classificacoes = pd.read_sql(query_classificacoes, conn)\n",
      "C:\\Users\\Gabriel D. Barros\\AppData\\Local\\Temp\\ipykernel_39524\\956150992.py:106: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_mudancas['data_atualizacao'] = data_atualizacao\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Conectar ao banco de dados MySQL via ODBC usando DSN\n",
    "dsn_name = 'segvojoana'\n",
    "conn = pyodbc.connect(f'DSN={dsn_name};')\n",
    "\n",
    "# Etapa 1: Consulta para obter os dados necessários\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    ped.ped_pescodigo, \n",
    "    ped.ped_dtemissao, \n",
    "    pes.pes_razao, \n",
    "    pes.pes_fantasia, \n",
    "    ped.ped_pesobruto, \n",
    "    pes.pes_clccodigo, \n",
    "    cli.cli_cclcodigoe, \n",
    "    ccl.ccl_desc AS carteira_cliente\n",
    "FROM \n",
    "    pedidos ped\n",
    "JOIN \n",
    "    pessoa pes ON ped.ped_pescodigo = pes.pes_codigo\n",
    "JOIN \n",
    "    cliente cli ON pes.pes_codigo = cli.cli_pescodigo\n",
    "LEFT JOIN \n",
    "    carteiracli ccl ON cli.cli_cclcodigoe = ccl.ccl_codigo\n",
    "WHERE \n",
    "    ped.ped_natcodigo IN ('VEN', 'VES', 'VIN', 'VIS') \n",
    "    AND ped.ped_pescodigo <> 1 \n",
    "    AND ped.ped_stpcodigo = 6\n",
    "    AND ped.ped_dtemissao >= DATE_SUB(CURRENT_DATE, INTERVAL 12 MONTH);\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "\n",
    "# Consultar classificações\n",
    "query_classificacoes = \"\"\"\n",
    "SELECT clc_codigo, clc_desc\n",
    "FROM classificapes;\n",
    "\"\"\"\n",
    "df_classificacoes = pd.read_sql(query_classificacoes, conn)\n",
    "\n",
    "# Fechar conexão após carregar os dados\n",
    "conn.close()\n",
    "\n",
    "# Criar um dicionário de mapeamento de código para descrição\n",
    "codigo_to_desc = df_classificacoes.set_index('clc_codigo')['clc_desc'].to_dict()\n",
    "\n",
    "# Etapa 2: Preparar os dados\n",
    "df['ped_dtemissao'] = pd.to_datetime(df['ped_dtemissao'])\n",
    "df['mes_ano'] = df['ped_dtemissao'].dt.to_period('M')\n",
    "\n",
    "# Agrupar e calcular média mensal de peso por cliente\n",
    "df_grouped = df.groupby(['ped_pescodigo', 'pes_razao', 'pes_fantasia', 'mes_ano']).agg(total_peso=('ped_pesobruto', 'sum')).reset_index()\n",
    "df_final = df_grouped.groupby(['ped_pescodigo', 'pes_razao', 'pes_fantasia']).agg(media_peso_mensal=('total_peso', 'mean')).reset_index()\n",
    "\n",
    "# Segmentar clientes\n",
    "def segmentar(peso):\n",
    "    if peso > 599:\n",
    "        return 'CLIENTE A'\n",
    "    elif peso >= 400:\n",
    "        return 'CLIENTE B'\n",
    "    elif peso >= 200:\n",
    "        return 'CLIENTE C'\n",
    "    elif peso >= 80:\n",
    "        return 'CLIENTE D'\n",
    "    elif peso > 0:\n",
    "        return 'CLIENTE E'\n",
    "\n",
    "# Adicionar segmento baseado na média de peso mensal\n",
    "df_final['desc_clc_nova'] = df_final['media_peso_mensal'].apply(segmentar)\n",
    "\n",
    "# Garantir que `df` tenha valores únicos para `ped_pescodigo`\n",
    "df_unique = df.drop_duplicates(subset='ped_pescodigo')\n",
    "\n",
    "# Adicionar descrição da classificação atual\n",
    "df_final['pes_clccodigo'] = df_final['ped_pescodigo'].map(\n",
    "    df_unique.set_index('ped_pescodigo')['pes_clccodigo']\n",
    ")\n",
    "df_final['desc_clc_atual'] = df_final['pes_clccodigo'].map(codigo_to_desc)\n",
    "\n",
    "# Definir hierarquia explícita\n",
    "hierarquia = ['CLIENTE E', 'CLIENTE D', 'CLIENTE C', 'CLIENTE B', 'CLIENTE A']\n",
    "\n",
    "# Identificar mudanças de classificação\n",
    "def identificar_mudanca(row):\n",
    "    atual_pos = hierarquia.index(row['desc_clc_atual']) if row['desc_clc_atual'] in hierarquia else -1\n",
    "    nova_pos = hierarquia.index(row['desc_clc_nova']) if row['desc_clc_nova'] in hierarquia else -1\n",
    "\n",
    "    if atual_pos == -1 and nova_pos != -1:\n",
    "        return 'Upgrade'\n",
    "    elif nova_pos > atual_pos:\n",
    "        return 'Upgrade'\n",
    "    elif nova_pos < atual_pos:\n",
    "        return 'Downgrade'\n",
    "    else:\n",
    "        return 'Sem alteração'\n",
    "\n",
    "df_final['mudanca'] = df_final.apply(identificar_mudanca, axis=1)\n",
    "\n",
    "# Filtrar apenas clientes com mudanças relevantes\n",
    "df_mudancas = df_final[df_final['mudanca'] != 'Sem alteração']\n",
    "\n",
    "# Adicionar a data da atualização\n",
    "data_atualizacao = datetime.now().strftime('%Y-%m-%d')\n",
    "df_mudancas['data_atualizacao'] = data_atualizacao\n",
    "\n",
    "# Adicionar informações da carteira ao relatório\n",
    "df_mudancas = df_mudancas.merge(\n",
    "    df[['ped_pescodigo', 'carteira_cliente']].drop_duplicates(),\n",
    "    on='ped_pescodigo',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Gerar relatório em CSV com a vírgula como separador decimal\n",
    "df_mudancas[['ped_pescodigo', 'pes_razao', 'pes_fantasia', 'carteira_cliente', 'desc_clc_atual', 'desc_clc_nova', 'media_peso_mensal', 'mudanca', 'data_atualizacao']].to_csv(\n",
    "    'Relatorio_Alteracoes_Classificacaoxx.csv', index=False, sep=';', decimal=',', encoding='utf-8'\n",
    ")\n",
    "\n",
    "# Gerar script SQL para atualizar as classificações\n",
    "sql_commands = []\n",
    "for _, row in df_final.iterrows():\n",
    "    sql = f\"UPDATE pessoa SET pes_clccodigo = (SELECT clc_codigo FROM classificapes WHERE clc_desc = '{row['desc_clc_nova']}') WHERE pes_codigo = {row['ped_pescodigo']};\"\n",
    "    sql_commands.append(sql)\n",
    "\n",
    "with open('atualizar_classificacaoxx.sql', 'w', encoding='utf-8') as file:\n",
    "    file.write('\\n'.join(sql_commands))\n",
    "\n",
    "print(\"Relatório em CSV e script SQL gerados com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29caa5bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
